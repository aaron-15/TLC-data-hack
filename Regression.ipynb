{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The taxi trip duration prediction can help people to plan their trips ahead of time.\n",
    "\n",
    "Problem - Which variables will help in predicting the trip duration correctly?\n",
    "\n",
    "The trip duration is mainly a function of road network, speed, weather, time of the day, season, weekday or weekend, month.\n",
    "I have not used the road network data for the model. However, the other variables and their data is available. The taxi dataset, along with the weather data is used to create the predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import scipy.stats as sc\n",
    "import datetime as dt\n",
    "import shapely as sh\n",
    "import geopandas as gp\n",
    "import pysal as ps\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "from sklearn.model_selection import GridSearchCV as GSC\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./Cleaned_data/train.csv\")\n",
    "train.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "test = pd.read_csv(\"./Cleaned_data/test.csv\")\n",
    "test.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyct = gp.read_file('./nyct2010_17c/nyct2010.shp')\n",
    "nyct.to_crs(epsg=4326, inplace=True)\n",
    "nyct = nyct[['BoroCT2010', 'BoroName', 'geometry']]\n",
    "manh_ct = nyct[nyct.BoroName == 'Manhattan']\n",
    "manh_ct.BoroCT2010 = manh_ct.BoroCT2010.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_p = pd.read_csv(\"./Cleaned_data/tp.csv\")\n",
    "train_d = pd.read_csv(\"./Cleaned_data/td.csv\")\n",
    "test_p = pd.read_csv(\"./Cleaned_data/testp.csv\")\n",
    "test_d = (pd.read_csv(\"./Cleaned_data/testd.csv\"))\n",
    "\n",
    "train_p.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "train_d.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "test_p.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "test_d.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "train_p = pd.merge(train_p, manh_ct, how='inner', on='BoroCT2010')\n",
    "train_d = pd.merge(train_d, manh_ct, how='inner', on='BoroCT2010')\n",
    "test_p = pd.merge(test_p, manh_ct, how='inner', on='BoroCT2010')\n",
    "test_d = pd.merge(test_d, manh_ct, how='inner', on='BoroCT2010')\n",
    "\n",
    "train_p = train_p[['id', 'BoroCT2010']]\n",
    "train_p.columns = ['id', 'pickup_ct']\n",
    "\n",
    "train_d = train_d[['id', 'BoroCT2010']]\n",
    "train_d.columns = ['id', 'dropoff_ct']\n",
    "\n",
    "test_p = test_p[['id', 'BoroCT2010']]\n",
    "test_p.columns = ['id', 'pickup_ct']\n",
    "\n",
    "test_d = test_d[['id', 'BoroCT2010']]\n",
    "test_d.columns = ['id', 'dropoff_ct']\n",
    "\n",
    "train_ct = pd.merge(train_p, train_d, how='inner', on='id')\n",
    "test_ct = pd.merge(test_p, test_d, how='inner', on='id')\n",
    "\n",
    "test = pd.merge(test, test_ct, how='inner', on='id')\n",
    "train = pd.merge(train, train_ct, how='inner', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the temporal variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\n",
    "train['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)\n",
    "\n",
    "test['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\n",
    "\n",
    "train['pickup_date'] = train.pickup_datetime.dt.date\n",
    "test['pickup_date'] = test.pickup_datetime.dt.date\n",
    "\n",
    "train['hourofday'] = (train.pickup_datetime.dt.hour*60.0 + train.pickup_datetime.dt.minute)/60.0\n",
    "train['Dayofweek'] = train.pickup_datetime.dt.dayofweek\n",
    "train['monthofyear'] = train.pickup_datetime.dt.month\n",
    "train['dayofmonth'] = train.pickup_datetime.dt.day\n",
    "\n",
    "test['hourofday'] = test.pickup_datetime.dt.hour\n",
    "test['Dayofweek'] = test.pickup_datetime.dt.dayofweek\n",
    "test['monthofyear'] = test.pickup_datetime.dt.month\n",
    "test['dayofmonth'] = test.pickup_datetime.dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the haversine distance and direction, eucledian would also have worked  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function taken from - https://www.kaggle.com/karelrv/nyct-from-a-to-z-with-xgboost-tutorial/notebook\n",
    "\n",
    "def haversine_array(lat1, lng1, lat2, lng2):\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return h\n",
    "\n",
    "\n",
    "def bearing_array(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, \n",
    "                                                     train['pickup_longitude'].values, \n",
    "                                                     train['dropoff_latitude'].values, \n",
    "                                                     train['dropoff_longitude'].values)\n",
    "\n",
    "test.loc[:, 'distance_haversine'] = haversine_array(test['pickup_latitude'].values, \n",
    "                                                    test['pickup_longitude'].values, \n",
    "                                                    test['dropoff_latitude'].values, \n",
    "                                                    test['dropoff_longitude'].values)    \n",
    "\n",
    "train.loc[:, 'direction'] = bearing_array(train['pickup_latitude'].values, \n",
    "                                          train['pickup_longitude'].values, \n",
    "                                          train['dropoff_latitude'].values, \n",
    "                                          train['dropoff_longitude'].values)\n",
    "\n",
    "test.loc[:, 'direction'] = bearing_array(test['pickup_latitude'].values, \n",
    "                                         test['pickup_longitude'].values, \n",
    "                                         test['dropoff_latitude'].values, \n",
    "                                         test['dropoff_longitude'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.store_and_fwd_flag = (train.store_and_fwd_flag == 'Y').astype('int')\n",
    "test.store_and_fwd_flag = (test.store_and_fwd_flag == 'Y').astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temporal characteristics of the pickups, dropoffs during the weekday and weekend taken from the 'Hourly pattern Spatial clustering' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temporal = pd.read_csv('./Cleaned_data/temporal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'BoroCT2010', u'morning_pickups_wd_trip_dur',\n",
       "       u'morning_pickups_wd', u'afternoon_pickups_wd_trip_dur',\n",
       "       u'afternoon_pickups_wd', u'evening_pickups_wd_trip_dur',\n",
       "       u'evening_pickups_wd', u'night_pickups_wd_trip_dur',\n",
       "       u'night_pickups_wd', u'morning_dropoffs_wd_trip_dur',\n",
       "       u'morning_dropoffs_wd', u'afternoon_dropoffs_wd_trip_dur',\n",
       "       u'afternoon_dropoffs_wd', u'evening_dropoffs_wd_trip_dur',\n",
       "       u'evening_dropoffs_wd', u'night_dropoffs_wd_trip_dur',\n",
       "       u'night_dropoffs_wd', u'morning_pickups_we_trip_dur',\n",
       "       u'morning_pickups_we', u'afternoon_pickups_we_trip_dur',\n",
       "       u'afternoon_pickups_we', u'evening_pickups_we_trip_dur',\n",
       "       u'evening_pickups_we', u'night_pickups_we_trip_dur',\n",
       "       u'night_pickups_we', u'morning_dropoffs_we_trip_dur',\n",
       "       u'morning_dropoffs_we', u'afternoon_dropoffs_we_trip_dur',\n",
       "       u'afternoon_dropoffs_we', u'evening_dropoffs_we_trip_dur',\n",
       "       u'evening_dropoffs_we', u'night_dropoffs_we_trip_dur',\n",
       "       u'night_dropoffs_we'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temporal = temporal[[u'BoroCT2010', u'morning_pickups_wd',  u'afternoon_pickups_wd', \n",
    "                     u'evening_pickups_wd',\n",
    "       u'night_pickups_wd', \n",
    "       u'morning_dropoffs_wd',\n",
    "       u'afternoon_dropoffs_wd', \n",
    "       u'evening_dropoffs_wd', \n",
    "       u'night_dropoffs_wd', \n",
    "       u'morning_pickups_we', \n",
    "       u'afternoon_pickups_we', \n",
    "       u'evening_pickups_we', \n",
    "       u'night_pickups_we',\n",
    "       u'morning_dropoffs_we',\n",
    "       u'afternoon_dropoffs_we', \n",
    "       u'evening_dropoffs_we',\n",
    "       u'night_dropoffs_we']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.merge(train, temporal, left_on='pickup_ct', right_on='BoroCT2010')\n",
    "train  = pd.merge(train, temporal, left_on='dropoff_ct', right_on='BoroCT2010')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have taken the average temperature, snowfall and precipitation as predictors. Taxi speed does depend on the precipitation and snowfall as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"./weather_data_nyc_centralpark_2016.csv\")\n",
    "\n",
    "weather.date = pd.to_datetime(weather.date).dt.date\n",
    "\n",
    "weather = weather[['date', 'average temperature', 'precipitation', 'snow fall']]\n",
    "\n",
    "weather.loc[weather.precipitation == 'T','precipitation'] = 0.001\n",
    "\n",
    "weather.loc[weather['snow fall'] == 'T','snow fall'] = 0.001\n",
    "\n",
    "weather.precipitation = weather.precipitation.astype('float')\n",
    "weather['snow fall'] = weather['snow fall'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, weather, left_on='pickup_date', right_on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'vendor_id', u'pickup_datetime', u'dropoff_datetime',\n",
       "       u'passenger_count', u'pickup_longitude', u'pickup_latitude',\n",
       "       u'dropoff_longitude', u'dropoff_latitude', u'store_and_fwd_flag',\n",
       "       u'trip_duration', u'pickup_ct', u'dropoff_ct', u'pickup_date',\n",
       "       u'hourofday', u'Dayofweek', u'monthofyear', u'dayofmonth',\n",
       "       u'distance_haversine', u'direction', u'date', u'average temperature',\n",
       "       u'precipitation', u'snow fall', u'BoroCT2010_x',\n",
       "       u'morning_pickups_wd_x', u'afternoon_pickups_wd_x',\n",
       "       u'evening_pickups_wd_x', u'night_pickups_wd_x',\n",
       "       u'morning_dropoffs_wd_x', u'afternoon_dropoffs_wd_x',\n",
       "       u'evening_dropoffs_wd_x', u'night_dropoffs_wd_x',\n",
       "       u'morning_pickups_we_x', u'afternoon_pickups_we_x',\n",
       "       u'evening_pickups_we_x', u'night_pickups_we_x',\n",
       "       u'morning_dropoffs_we_x', u'afternoon_dropoffs_we_x',\n",
       "       u'evening_dropoffs_we_x', u'night_dropoffs_we_x', u'BoroCT2010_y',\n",
       "       u'morning_pickups_wd_y', u'afternoon_pickups_wd_y',\n",
       "       u'evening_pickups_wd_y', u'night_pickups_wd_y',\n",
       "       u'morning_dropoffs_wd_y', u'afternoon_dropoffs_wd_y',\n",
       "       u'evening_dropoffs_wd_y', u'night_dropoffs_wd_y',\n",
       "       u'morning_pickups_we_y', u'afternoon_pickups_we_y',\n",
       "       u'evening_pickups_we_y', u'night_pickups_we_y',\n",
       "       u'morning_dropoffs_we_y', u'afternoon_dropoffs_we_y',\n",
       "       u'evening_dropoffs_we_y', u'night_dropoffs_we_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am training a random forest model, I have not tuned the parameters here, since the computation time is too high.\n",
    "The model trains a subset of the train data provided and used the remaining train data to test the prediction. The test data provided does not have trip duration, it is not used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1220.11,   585.33,  1088.79, ...,   325.55,   296.34,   561.16])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train[[u'vendor_id',\n",
    "       u'passenger_count',\n",
    "       u'store_and_fwd_flag',\n",
    "       u'hourofday', u'Dayofweek', u'monthofyear', u'dayofmonth',\n",
    "       u'distance_haversine', u'direction', u'average temperature',\n",
    "       u'precipitation', u'snow fall',\n",
    "       u'morning_pickups_wd_x', u'afternoon_pickups_wd_x',\n",
    "       u'evening_pickups_wd_x', u'night_pickups_wd_x',\n",
    "       u'morning_dropoffs_wd_x', u'afternoon_dropoffs_wd_x',\n",
    "       u'evening_dropoffs_wd_x', u'night_dropoffs_wd_x',\n",
    "       u'morning_pickups_we_x', u'afternoon_pickups_we_x',\n",
    "       u'evening_pickups_we_x', u'night_pickups_we_x',\n",
    "       u'morning_dropoffs_we_x', u'afternoon_dropoffs_we_x',\n",
    "       u'evening_dropoffs_we_x', u'night_dropoffs_we_x',\n",
    "       u'morning_pickups_wd_y', u'afternoon_pickups_wd_y',\n",
    "       u'evening_pickups_wd_y', u'night_pickups_wd_y',\n",
    "       u'morning_dropoffs_wd_y', u'afternoon_dropoffs_wd_y',\n",
    "       u'evening_dropoffs_wd_y', u'night_dropoffs_wd_y',\n",
    "       u'morning_pickups_we_y', u'afternoon_pickups_we_y',\n",
    "       u'evening_pickups_we_y', u'night_pickups_we_y',\n",
    "       u'morning_dropoffs_we_y', u'afternoon_dropoffs_we_y',\n",
    "       u'evening_dropoffs_we_y', u'night_dropoffs_we_y']]\n",
    "\n",
    "y = train[['trip_duration']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=4)\n",
    "\n",
    "# param_grid = {'n_estimators' = 100, 'max_features'='sqrt', 'max_leaf_nodes' : range(2,25)}\n",
    "# gr=GSC(rf1,param_grid=param_grid)\n",
    "# rf = gr.fit(X_train, Y_train)\n",
    "\n",
    "regr_rf = RandomForestRegressor(n_estimators=100, random_state=2)\n",
    "regr_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on new data\n",
    "y_rf = regr_rf.predict(X_test)\n",
    "\n",
    "y_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(predicted,real):\n",
    "    sum=0.0\n",
    "    for x in range(len(predicted)):\n",
    "        p = np.log(predicted[x]+1)\n",
    "        r = np.log(real[x]+1)\n",
    "        sum = sum + (p - r)**2\n",
    "    return (sum/len(predicted))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34888875])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsle(y_rf, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metric used for testing the prediction is \"Root mean squared log error\". This metric is used, since the data available has some wrong trip durations which are high. The log terms in the metric does not give high weight to large error value, hence it is useful in this case to test our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('store_and_fwd_flag', 0.0004335677949985082),\n",
       " ('snow fall', 0.0018016095636730792),\n",
       " ('vendor_id', 0.0030700146257975195),\n",
       " ('afternoon_pickups_we_y', 0.0043009891791907845),\n",
       " ('afternoon_pickups_wd_x', 0.0046797959354161608),\n",
       " ('evening_dropoffs_we_y', 0.0046805545639881669),\n",
       " ('afternoon_dropoffs_wd_x', 0.0047524916321065981),\n",
       " ('afternoon_dropoffs_we_y', 0.0047723380498469019),\n",
       " ('evening_dropoffs_we_x', 0.0048286807822754442),\n",
       " ('afternoon_pickups_we_x', 0.0048496471983468618),\n",
       " ('evening_pickups_we_x', 0.0048804088212757299),\n",
       " ('afternoon_dropoffs_we_x', 0.0049557608351794508),\n",
       " ('evening_dropoffs_wd_y', 0.0050545346995461062),\n",
       " ('afternoon_dropoffs_wd_y', 0.0051427189344980476),\n",
       " ('morning_dropoffs_we_y', 0.0051802570201373585),\n",
       " ('evening_dropoffs_wd_x', 0.00524006067663453),\n",
       " ('afternoon_pickups_wd_y', 0.0053190031085163349),\n",
       " ('morning_dropoffs_we_x', 0.0055837277899482137),\n",
       " ('evening_pickups_we_y', 0.0056676787630421136),\n",
       " ('morning_pickups_we_y', 0.0057046767659042399),\n",
       " ('morning_pickups_wd_y', 0.0057473016880637941),\n",
       " ('night_pickups_wd_x', 0.0058700573985989556),\n",
       " ('night_pickups_wd_y', 0.00611012376988834),\n",
       " ('morning_pickups_wd_x', 0.0063125635712621394),\n",
       " ('morning_pickups_we_x', 0.0063337851633360684),\n",
       " ('evening_pickups_wd_x', 0.0065609358482337145),\n",
       " ('night_dropoffs_we_y', 0.0068544112284269054),\n",
       " ('passenger_count', 0.007084053057458994),\n",
       " ('night_dropoffs_wd_x', 0.007337780444099524),\n",
       " ('morning_dropoffs_wd_x', 0.0073633115966003446),\n",
       " ('evening_pickups_wd_y', 0.0078195579795680252),\n",
       " ('night_dropoffs_we_x', 0.0079275932906748177),\n",
       " ('night_pickups_we_x', 0.0096562426151371051),\n",
       " ('precipitation', 0.0097032782127722469),\n",
       " ('morning_dropoffs_wd_y', 0.009775515930376847),\n",
       " ('night_pickups_we_y', 0.012431391656786321),\n",
       " ('night_dropoffs_wd_y', 0.013265719323228287),\n",
       " ('monthofyear', 0.014193352475991107),\n",
       " ('dayofmonth', 0.021109995587087656),\n",
       " ('average temperature', 0.022045320294115264),\n",
       " ('Dayofweek', 0.036702406939839297),\n",
       " ('direction', 0.073908647817126097),\n",
       " ('hourofday', 0.10528769552784385),\n",
       " ('distance_haversine', 0.4997004418431622)]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = {}\n",
    "for idx, feat in enumerate(regr_rf.feature_importances_):\n",
    "    feat_imp[X_test.columns[idx]] = feat\n",
    "\n",
    "sorted(feat_imp.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important features we get are distance, direction and the time variables. The snow fall, vendor id, store and fwd flag are not contributing much to the trip duration. The variables created for morning, evening, night, afternoon could have been handled more elegantly. The pickups and dropoffs could have been segregated as morning and evening and weekday, weekend, that could have been more better. The importance of those temporal variables may be relative and can change in different iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model was created with 100 estimators, i.e 100 random trees were created, that was a computationally expensive and taking more time, so in the below model, I have reduced the number of estimators to 10 and removed the less important features. The rmsle has increased but that can be because of the reduced estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36560705])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train[[u'passenger_count',\n",
    "           u'hourofday', u'Dayofweek', u'monthofyear', u'dayofmonth',\n",
    "       u'distance_haversine', u'direction', u'average temperature',\n",
    "       u'precipitation', u'morning_pickups_wd_x', u'afternoon_pickups_wd_x',\n",
    "       u'evening_pickups_wd_x', u'night_pickups_wd_x',\n",
    "       u'morning_dropoffs_wd_x', u'afternoon_dropoffs_wd_x',\n",
    "       u'evening_dropoffs_wd_x', u'night_dropoffs_wd_x',\n",
    "       u'morning_pickups_we_x', u'afternoon_pickups_we_x',\n",
    "       u'evening_pickups_we_x', u'night_pickups_we_x',\n",
    "       u'morning_dropoffs_we_x', u'afternoon_dropoffs_we_x',a\n",
    "       u'evening_dropoffs_we_x', u'night_dropoffs_we_x',\n",
    "       u'morning_pickups_wd_y', u'afternoon_pickups_wd_y',\n",
    "       u'evening_pickups_wd_y', u'night_pickups_wd_y',\n",
    "       u'morning_dropoffs_wd_y', u'afternoon_dropoffs_wd_y',\n",
    "       u'evening_dropoffs_wd_y', u'night_dropoffs_wd_y',\n",
    "       u'morning_pickups_we_y', u'afternoon_pickups_we_y',\n",
    "       u'evening_pickups_we_y', u'night_pickups_we_y',\n",
    "       u'morning_dropoffs_we_y', u'afternoon_dropoffs_we_y',\n",
    "       u'evening_dropoffs_we_y', u'night_dropoffs_we_y']]\n",
    "\n",
    "y = train[['trip_duration']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=4)\n",
    "\n",
    "max_depth = 30\n",
    "\n",
    "regr_rf = RandomForestRegressor(max_depth=max_depth, random_state=2)\n",
    "regr_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on new data\n",
    "y_rf = regr_rf.predict(X_test)\n",
    "\n",
    "rmsle(y_rf, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('afternoon_pickups_we_y', 0.0040900255780398674),\n",
       " ('evening_dropoffs_we_y', 0.0046903922481110012),\n",
       " ('afternoon_pickups_wd_x', 0.0047790221493969696),\n",
       " ('afternoon_dropoffs_wd_x', 0.0047871267267194234),\n",
       " ('afternoon_dropoffs_wd_y', 0.0048786908114831331),\n",
       " ('afternoon_dropoffs_we_y', 0.0048838054589743288),\n",
       " ('evening_pickups_we_x', 0.0048846124686470205),\n",
       " ('evening_dropoffs_we_x', 0.0049300215369272047),\n",
       " ('afternoon_pickups_wd_y', 0.0049334423791533881),\n",
       " ('afternoon_dropoffs_we_x', 0.0050129397396574829),\n",
       " ('evening_dropoffs_wd_y', 0.0050159933581870823),\n",
       " ('afternoon_pickups_we_x', 0.0050534245613028574),\n",
       " ('evening_dropoffs_wd_x', 0.0051777120959275889),\n",
       " ('morning_dropoffs_we_y', 0.0052931458408999521),\n",
       " ('morning_dropoffs_we_x', 0.0057595936307841596),\n",
       " ('morning_pickups_we_y', 0.005791092642840604),\n",
       " ('night_pickups_wd_y', 0.0058156659446132542),\n",
       " ('morning_pickups_wd_y', 0.0058248800319478655),\n",
       " ('night_pickups_wd_x', 0.0059623843115627758),\n",
       " ('evening_pickups_we_y', 0.0060600803196096927),\n",
       " ('morning_pickups_wd_x', 0.0063392032097951256),\n",
       " ('evening_pickups_wd_x', 0.0066579698111664852),\n",
       " ('morning_pickups_we_x', 0.0067858610971398559),\n",
       " ('night_dropoffs_we_y', 0.0067993926529540255),\n",
       " ('morning_dropoffs_wd_x', 0.0071348437898770597),\n",
       " ('night_dropoffs_wd_x', 0.0072845701334598835),\n",
       " ('passenger_count', 0.0073555671994185055),\n",
       " ('night_dropoffs_we_x', 0.0075483476614784176),\n",
       " ('evening_pickups_wd_y', 0.0079836828685200187),\n",
       " ('morning_dropoffs_wd_y', 0.0092719668586308829),\n",
       " ('precipitation', 0.0097099482701034946),\n",
       " ('night_pickups_we_x', 0.0098148919781678827),\n",
       " ('night_pickups_we_y', 0.012285063743094373),\n",
       " ('night_dropoffs_wd_y', 0.013563438275743953),\n",
       " ('monthofyear', 0.01414349094319697),\n",
       " ('dayofmonth', 0.020626199550331396),\n",
       " ('average temperature', 0.022520329833689227),\n",
       " ('Dayofweek', 0.036880402303424431),\n",
       " ('direction', 0.076669754749265268),\n",
       " ('hourofday', 0.10578573260351354),\n",
       " ('distance_haversine', 0.50121529063224357)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = {}\n",
    "for idx, feat in enumerate(regr_rf.feature_importances_):\n",
    "    feat_imp[X_test.columns[idx]] = feat\n",
    "\n",
    "sorted(feat_imp.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trip duration can be predicted from the selected features, more imporvment can be made to the models. But this is more of a network analysis problem and can be solved more accurately by network analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
